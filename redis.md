# redis集群方案

## 1. 主从高可用方案

## 2.客户端分片:典型的jedis分片
### 2.1 维护了两个map：
  
  一个TreeMap，Hash(shardInfo)<->JedisShardInfo,每个JedisShardInfo的hash值及其对应的JedisShardInfo
  
  一个LinkedHashMap，JedisShardInfo <->Jedis，每个JedisShardInfo及其对应的Jedis实例
  
  初始化：JedisShardInfo -> ShardedJedisPool(基于apache的common-pool2的对象池实现，borrorObject()方法，调用ShardedJedisFactory创建对象) -> ShardedJedis
        -> BinaryShardedJedis -> Sharded <Jedis, JedisShardInfo>(维护两个map)；
  
  数据定位：获取的时候调用ShardedJedis的getShard方法获取一个Jedis实例，具体对key做hash，去TreeMap中判断，当前的key落在哪个区间上，根据该区间上的shardInfo去获取对应的Jedis实例；
### 2.2 分片算法：
  
    redis.clients.jedis.util.Sharded#initialize()
    
    1. 根据redis节点集合创建虚拟节点(160*weight),根据每个redis节点的name计算出对应的hash值，如果没有配置节点名称，使用默认的名称；
    
    2. 将hash值和对应的JedisShardInfo放入TreeMap中，将JedisShardInfo和对应的Jedis实例放入LinkedHashMap中去；
    
    redis.clients.jedis.util.Sharded#getShard(java.lang.String)
    
    3.通过key或者keyTag计算出hash值，在TreeMap中找到比这个hash值大的第一个虚拟节点(这个过程是在一致性hash环上顺时针查找的过程)，
    然后获取对应的JedisShardInfo,在LinkedHashMap中获取对应的Jedis实例
### 2.3 缺陷
1. 不支持涉及到多个key操作的命令，因为分片时这些key可能会被分到不同的redis节点中去，读操作时，响应时间等于响应最慢的那个redis节点的时间，
    写操作时，可能会同时去写多个redis节点，可能会出现部分key写入成功，部分写入失败，无法保证数据一致性的问题。
    
2. 只要有一个redis实例挂掉，该实例将会从连接池中移除，可能会造成数据丢失。

## 3.哨兵模式
### 3.1 简介
Sentinel模式： 一般包括3个sentinel节点，1个Master节点，1个Slave节点

Sentinel节点，用于监控Master和Slave的运行状态，并在Master节点down机的情况下，从slave中选择新的Master，并修改其他的Slave的Master

对于每个被Sentinel监视的主服务器来说，Sentinel会创建两个连向主服务器的异步(需要与多个实例创建多个网络连接)网络连接：
  1. 命令连接：专门用于向主服务器发送命令，并接收命令回复；
  2. 订阅连接：专门用于订阅主服务器的_sentinel_:hello频道，因为redis目前的发布与订阅功能中被发送的信息不会保存在redis服务器里面，为了不丢失该_sentinel_:hello频道的任何信息，
      必须使用一个订阅连接来接收该频繁的信息

主观下线：服务器在给定的毫秒数之内,没有返回 Sentinel 发送的 PING 命令的回复,或者返回一个错误,那么 Sentinel 将这个服务器标记为主观下线;

客观下线：多个Sentinel 实例在对同一个服务器做出下线判断，并且通过 SENTINEL is-master-down-by-addr 命令互相交流之后,得出的服务器下线判断(足够多的哨兵节点数量);
          哨兵之间进行一次投票，选出一个哨兵进行故障切换,切换成功后，通过发布订阅模式，让各个哨兵完成主从切换的监控。

哨兵的定时任务：

  1. 每个 Sentinel 以每秒钟一次的频率向它所知的主服务器、从服务器以及其他 Sentinel 实例发送一个 PING 命令;
  
  2. 在一般情况下， 每个 Sentinel 会以每 10 秒一次的频率向它已知的所有主服务器和从服务器发送 INFO 命令，
    当一个主服务器被 Sentinel 标记为客观下线时， Sentinel 向下线主服务器的所有从服务器发送 INFO 命令的频率会从 10 秒一次改为每秒一次；
    
  3. 默认情况下，Sentinel会以每两秒一次的频率，通过命令连接向所有被监视的主服务器和从服务器的_sentinel_:hello频道发送信息
### 3.2 JedisSentinelPool简介
JedisSentinelPool -> redis.clients.jedis.JedisSentinelPool#initSentinels(1-4) -> redis.clients.jedis.JedisSentinelPool#initPool

1. 遍历sentinel地址，根据sentinel地址和端口，初始化Jedis；

2. 调用SENTINEL get-master-addr-by-name，根据主节点的名称获取主节点的地址和端口号，并初始化成HostAndPort；

3. 如果在任何一个sentinel地址中找到了master，就不再遍历；如果都没有找到，要么是所有的sentinels节点都down掉了，要么是master节点没有被存活的sentinels监控到；

4. 为每个sentinel都启动了一个监听器MasterListener，该监听器本身是一个守护线程，它会去订阅sentinel上关于master节点地址改变的消息;

5. master会与实例变量currentHostMaster(MasterListener发现主节点地址改变后，会改变该值)作比较是否相等，相等则重新设置地址，不等且是第一次调用，则初始化GenericObjectPool。

### 3.3 JedisSentinelPool的总结
1. 仅仅适用于单个master-slave，不能进行数据分片
## 4. cluster模式
### 4.1 简介
  1. 主从和哨兵模式单个节点的存储能力有限，访问能力有限，集群模式具有高可用、可扩展性、分布式、容错等特性。
  
  2. redis集群有2^14=16384个哈希槽，每个key通过CRC16校验后对16384取模来决定放置在哪个槽位，集群中的每个节点负责一部分hash槽；
  
    (注:为什么使用16384个slots？)
    
    2.1 CRC16算法产生的hash值有16bit，可以产生2^16=65536个值。因为redis节点在发送心跳包时需要包含所有的槽位信息，以便让节点知道当前集群的信息，16384=16k，
    在发送心跳包时，进行bitmap压缩，压缩后2*8(bit)*1024(1k)=2k，即可以使用2k的空间创建16K的槽位信息，如果采用65536bit，经压缩后需要8k的空间，浪费带宽。
    
    2.2 redis的集群主节点数量基本不可能超过1000个，集群节点越多，心跳包的消息体内携带的数据就越多，如果超过1000个，会导致网络拥堵，因此不建议节点数据超过1000，
    因此对于节点数在1000以内的redis集群，16384个槽位已经够用，没必要再扩展到65536；
    
    2.3 相对而言，槽位越小，节点少的情况下，压缩比高，因为采用bitmap进行压缩，其填充率为slots/节点数
    
  3. redis集群只允许节点操作自己分片的数据，目前只支持具有相同slot值的key进行批量操作，对于映射为不同slot值的key执行批量操作时可能存在于多个节点上，会抛异常
  
    (注：可以使用键哈希标签(Keys hash tags)在集群稳定、没有做碎片重组的情况下允许多键操作)
    
    3.1 如果键值不包含{,则计算键的哈希值
    
    3.2 如果不是直接计算键的哈希，只有在第一个 { 和它右边第一个 } 之间的内容会被用来计算哈希值，如果两个字符之间没有任何字符，则计算整个键的哈希值。
    
  4. 常见的数据分片算法：范围分片、哈希分片、一致性哈希算法和虚拟哈希槽等
    
   一致性哈希算法：
   
    解决的问题：在分布式系统中，动态的增加或减少节点时，造成的数据映射变化最小，并且尽可能使内容比较均匀的分布在每个节点上。
    
    特点：
        
        1. 平衡性：哈希的结果尽可能的分布到所有缓存节点中去
        2. 单调性：如果已经有内容通过哈希分派到了相应的缓冲区中去，又有新的缓冲区加入到系统，哈希的结果应该能够保证原有已分配的内容可以被映射到原有的或者新的缓冲区中去，而不会被映射到旧的缓冲集中的其他缓冲区。
        3. 分散性：分布式环境中，终端有可能看不到所有的缓冲，而是只能看到其中的一部分，不同的终端所见的缓冲范围有可能不同，导致哈希的结果不一致，最终的结果可能是相同的内容被不同的终端映射到不同的缓冲区中去。分散性指的是这种情况发生的严重程度。
        4. 负载：对于一个特定的缓冲区，有可能被不同的用户映射为不同的内容
        5. 平滑性：缓存服务器的数目平滑改变和缓存对象的平滑改变是一致的
   原理：
    
       1. 将整个哈希值空间组织成一个虚拟的圆环(假设某哈希函数H的值空间为0-2^32-1)，整个空间按顺时针方向组织，0和2^32-1在零点方向重合；
       2. 将各个服务器使用hash函数进行哈希，确定其在哈希环上的位置；
       3. 将数据key使用相同的hash函数计算出哈希值，确定此数据在环上的位置，顺时针寻找到第一个存储节点；
       4. 如果一个节点不幸宕机，此时该节点的数据将会被重定位到顺时针方向的下一个节点。受影响的数据仅仅是此节点到其环空间的前一个节点之间的数据(逆时针方向遇到的第一个节点)，其他不受影响；
       5. 新增一个节点时，受影响的数据仅仅是新增节点到其环空间的前一个节点之间的数据(逆时针方向遇到的第一个节点)，其他不受影响；
       6. 数据倾斜问题：在服务节点太少时，容易因为节点分布不均匀而造成数据倾斜问题。引入了虚拟节点机制，对每一个服务节点计算多个哈希值，每个结果位置都放置一个此服务节点，称为虚拟节点，可以使得很少的服务节点也能做到相对均匀的数据分布。
    
### 4.2 JedisCluster简介
  1. 初始化：redis.clients.jedis.JedisClusterConnectionHandler#initializeSlotsCache
    
  ![Image_text](https://segmentfault.com/img/bV4Xpd?w=1031&h=471)
  
    在JedisClusterInfoCache中，保存pool的配置，维护了两个hashMap，Jedis <-> JedisPool，集群内所有节点及其对应的线程池，Slot <-> JedisPool，每个槽位对应的节点对象池;
    
    1.1 调用cluster slots命令获取所有槽位信息，List<Object>结构,其中Object表示List<Object>结构，包含每个节点的信息；
    序号0：哈希槽起始编号，序号1：哈希槽结束编号，序号2：主节点信息，包含ip地址、端口号、节点ID,序号3：从节点信息，包含ip地址、端口号、节点id
    
    1.2 维护每个节点的缓存Jedis <-> JedisPool,key是ip:port,vaule是JedisPool,维护主节点的缓存Slot <-> JedisPool
    
  2. 调用方法：redis.clients.jedis.JedisClusterCommand#run(java.lang.String)
 
    2.1 获取连接有三种方式
    第1种：默认null，执行命令发生错误，则根据节点生成缓存Jedis <-> JedisPool,并获取Jedis对象，
    如果键所在的槽位并没有指派给当前节点，节点返回一个MOVED_ERR，指引客户端redirect至正确的节点，说明缓存保存的集群配置信息有误，需要重新更新缓存，
    如果返回的ASK_ERR,表明集群正在重新分片，可能会出现被迁移的槽的一部分键值对保存在源节点里面，另一部分键值对则保存在目标节点里，返回ASK_ERR，指引客户端转向(redirect)正确的节点
    
    第2种：默认fasle，从集群中随机选择一个节点
    
    第3种：默认的方式，根据槽位定位节点，可避免MOVED_ERR。根据key找到对应的槽点，然后在缓存中获取对应的JedisPool，然后根据JedisPool池生成jedis对象(对象池)；
    如果没有找到对应的JedisPool，则清空缓存，重新更新缓存，在获取对应的JedisPool，仍未找到则从集群中随机选择一个节点
    
    (注ASK错误与MOVED错误)
    
    MOVED_ERR：集群中接收命令的节点，会计算出槽位，并检查槽位是否分配给自己，
    如果键所在的槽并没有指派给当前节点，那么节点会向客户端返回一个MOVED错误，指引客户端转向(redirect)至正确的节点，并再次发送之前想要执行的命令
    
    ASK_ERR：集群中的两个节点在迁移槽时，可能会出现被迁移的槽的一部分键值对保存在源节点里面，另一部分键值对则保存在目标节点里的情况，此时节点
    会先查找键key，如果找到了则直接执行客户端的命令，如果没有找到，则发送ASK_ERR，指引客户端转向(redirect)正确的节点。
    
    2.2 根据获取的正确连接(Jedis对象)，执行相应的redis命令，首先将命令写入RedisOutputStream，redis.clients.jedis.Connection#flush，
    将buf数组的命令写入到socket.outputStream流中，即将命令发送给了Redis。
 
    2.3 RedisInputStream装饰了socket.inputStream流，将其读取到缓存中，完成多次读取，根据返回结果前缀的不同，使用不同的方法解析流的信息。
 ## 5. 基于代理的redis分片
 ### 5.1 简介
    通常是在客户端和redis服务器直接启动一个代理服务proxy，客户端通过proxy与redis服务器进行交互，客户端不清楚proxy后方的redis服务器架构部署，
    redis服务的集群分片、架构变化都是由代理服务proxy来维护的。场景的proxy代理服务有twemproxy、codis等
    
    优点：
      可以解决客户端的redis分片的问题，例如客户端服务规模较大时，分片在客户端增加运维难度；后期redis扩容，需要修改客户端的配置，甚至重启客户端。
    缺点：
      由于中间多了一层代理转发，会造成一定程度上的性能下降，并且需要使用keepalived等保障proxy服务的高可用性
### 5.2 twemproxy简介
    具体见：https://github.com/twitter/twemproxy/

    一个redis和memcached的轻量级分布式代理；
    
    每个redis或memcached服务器保持一个长连接，这样在进行命令或数据传输时不需要再和后端的节点进行连接，加快传输效率；
    
    支持多个节点，且支持多个节点池，后端一台Redis挂掉后，Twemproxy能够自动摘除。恢复后，Twemproxy 能够自动识别、 恢复并重新加入到Redis组中重新使用；
    
    支持多节点的自动分片策略；
    
    通常只有一台Twemproxy在工作，另外一台处于备机，当一台挂掉以后，vip自动漂移，备机接替工作；
    
    单个TwemProxy的情况下，无论一个TwemProxy后面挂多少个Redis实例，其性能最多也只能达到单台Redis的性能；
    
    多台TwemProxy，客户端连接多台TwemProxy可在一定条件下提高性能。
    
    缺点：
    
    无法平滑地扩容/缩容，如果要新增一台redis，TwemProxy需要重启才能生效，且数据不会自动重新Reblance，需要人工单独写脚本来实现
    即redis节点发生数量变化时，TwemProxy算法相同的情况下，原来的数据必须重新处理分布，否则会存在找不到key值的情况；
    
    运维不友好，没有控制面板
    
    
    5.2.1 内存管理机制-零拷贝
    
    twemproxy通过mbuf结构管理内存，每个mbuf块的默认大小为16K，twemproxy的并发数与mbuf块的大小之间存在均衡关系。
    
    内存结构是可以复用的，使用重用池管理mbuf的内存，一旦分配了mbuf，它就不会被释放，而只是重新进入重用池，请求进入和响应输出的所有内存都在mbuf中进行分配，mbuf启用零拷贝，因为客户端接收请     求使用到的内存结构，后端服务器可以复用。同样，从服务器端接收响应时使用的mbuf，也可在客户端复用；

    内存池（mbuf）核心主要在nc_mbuf.ch中，所有mbuf几乎以单向链表的形式存储的
### 5.3 Codis简介
详情：https://github.com/CodisLabs/codis/blob/master/doc/tutorial_zh.md

    组件介绍：
    Codis Proxy:对外提供redis服务，除一些不支持的命令，和原生的redis无区别；
    
    Codis Dashboard：集群管理工具，支持集群的添加删除以及数据迁移操作，对于一个Codis集群，Dashboard最多部署一个；
    
    Codis Admin：集群管理的命令行工具；
    
    Codis FE：集群管理界面，多个Codis集群可以共用一个Codis FE，通过配置文件管理后端的codis-dashboard；
    
    Storage：集群提供外部存储，目前支持ZooKeeper、Etcd、Fs三种。；
    
    Codis Server：基于3.2.8分支开发，增加额外的数据结构，用来支持slot有关的操作及数据迁移指令。
 
    分片原理：
    
    使用预分片的技术来实现数据分片，默认分为1024个slot（0-1023）。Codis在接收到命令时，先对key进行crc32运算，然后再对1024取余，得到的结果就是对应的slot。
    
    此外，这个槽是可以配置，可以设置成 2048 或者是4096个。
    
    槽位与codis实例的关系维护在节点的内存中，各个节点之间的槽位信息通过zooKeeper监控同步。
    
    扩容操作：
    
    在扩容时，Codis提供了SLOTSSCAN指令，这个指令可以扫描指定的slot上的所有key，然后对每个key进行迁移，将这些key迁移到新的Redis的节点中。
    在迁移过程中，如果有key打进将要迁移或者正在迁移的旧槽位的时候，将这个key强制迁移到新的Redis节点中，然后再告诉Codis,下次如果有新的key的打在这个槽位中的话，那么转发到新的节点。
    
    缺点：
    
    不支持事务的，同时也会有一些命令行不支持；
    
    当主节点挂掉时，codis不会自动将某个从节点升级为主节点，当codis将某个slave升为master时，其他的slave并不会改变状态，仍然会从旧的master上同步数据，这就导致了主从数据不一致，
    当出现主从切换时，需要管理员手动创建新的sync action来完成数据同步;
    
    Zookeeper/etcd存放数据路由表和codis-proxy节点的元信息,如果zk出现问题，则可能导致数据不一致的情况甚至影响对外提供的服务。
  
   ## 6. redis数据结构
   
   TYPE命令：返回的是数据库键对应的值对象的类型，而不是键对象的类型
   
   OBJECT ENCODING命令：记录的是对象所使用的编码，即这个对象使用了什么数据结构作为对象的底层实现
   
   1. 字符串对象：编码可以是int、raw、embstr
   
    如果字符串对象保存的是一个字符串值，并且这个字符串值的长度大于32字节，对象的编码是raw，即简单动态字符串；
    
    如果字符串对象保存的是一个字符串值，并且这个字符串值的长度小于等于32字节，对象的编码是embstr，保存短字符的一种优化编码方式。
    
    如果字符串对象保存的是整数值，并且这个整数可以用long类型表示，对象的编码是int，使用整数值实现的字符串对象
    
  2. 列表对象：编码可以是ziplist或者linkedlist

    当列表对象满足这两个条件时，对象将使用ziplist编码，即压缩列表，每个压缩列表的节点保存一个列表元素
      
      1. 列表对象保存的所有字符串元素的长度都小于64字节；
      2. 列表对象保存的元素数量小于512个
   不能满足这两个条件的使用linkedlist，即双端链表，每个双端链表节点都保存了一个字符串对象，而每个字符串对象都保存了一个列表元素。
   
  3. 哈希对象：编码可以是ziplist或者hashtable
  
    当哈希对象满足以下两个条件时，使用ziplist编码，压缩列表：
    
      1. 当哈希对象保存的所有键值对的键和值的字符串长度都小于64字节；
      2. 哈希对象保存的键值对数量小于512个，这两个上限值可通过配置文件的参数作修改。
   存储方式：先将保存了键的压缩列表节点推入到压缩列表表尾，然后将保存了值的压缩列表节点推入到压缩列表表尾
   
      1. 保存了同一键值对的两个节点总是紧挨在一起，保存键的节点在前，保存值的节点在后；
      2. 先添加到哈希对象中的键值对会被放在压缩列表表头方向
      
    不能满足这个两个条件的使用hastable，字典作为底层实现：
    
      1.字典中的每个键都是一个字符串对象，对象中保存了键值对的键；
      2.字典中的每个值都是一个字符串对象，对象中保存了键值对的值
    
  4. 集合对象：编码可以是intset或者hashtable
    
    intset编码的集合对象使用整数集合作为底层实现，所有元素都被保存在整数集合里面，当满足以下两个条件时使用：
    
      1. 集合对象保存的所有元素都是整数值；
      2. 集合对象保存的元素数量不超过512个。
      
    不满足这两个条件的时候使用hashtable编码，使用字典作为底层实现，字典的每一个键都是一个字符串对象，每个字符串对象包含了一个集合元素，而字典的值则全部设置为NULL
    
  5. 有序集合对象：编码可以是ziplist或者skiplist
 
    ziplist编码的有序集合对象使用压缩列表作为底层实现，每个集合元素使用两个紧挨在一起的压缩列表节点来保存，第一个节点保存元素的成员，第二个节点保存元素的分值；
    压缩列表内的集合元素按分值从小到大进行排序，分值较小的元素被放置在靠近表头的方向，而分值较大的元素则放置在靠近表尾的方向，当满足以下两个条件时使用：
    
      1. 有序集合保存的元素数量小于128个；
      2. 有序集合保存的所有元素成员的长度都小于64字节。
      
    当不满足这两个条件的时候使用skiplist编码，采用zset结构作为底层实现，每个zset结构同时包含一个字典和一个跳跃表：
    
      1. 跳跃表按分值从小到大保存了所有集合元素，每个跳跃表节点都保存了一个集合元素，跳跃表节点的object属性保存了元素的成员，score属性保存了元素的分值，
      通过这个跳跃表可以对有序集合进行范围型操作,zrank、zrange
      
      2. 字典为有序集合创建了一个从成员到分值的映射，字典的每个键值对都保存了一个集合元素，字典的键保存了元素的成员，值保存了元素的分值，
      通过这个字典，可以通过O(1)复杂度查询给定成员的分值，例如zscore；
      
      3. 这两种数据结构都会通过指针来共享相同元素的成员和分值，因此同时使用跳跃表和字典来保存有序集合对象不会产生任何重复成员或者分值，不会造成额外的内存浪费
    
    
    
    
    
    
    
